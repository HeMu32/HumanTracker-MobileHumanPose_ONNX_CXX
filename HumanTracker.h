#ifndef POSE_DETECTOR_H
#define POSE_DETECTOR_H

#include <opencv2/opencv.hpp>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <chrono>
#include <vector>
#include <string>
#include <cmath>

#include "yolo_fast.h"
#include "mobileHumanPose.h"


#define INDIC_BOX_ASP 2.5
class HumanTracker
{
public:
    HumanTracker(const std::string& poseModelPath, const std::string& yoloModelPath);
    ~HumanTracker();
    
    /// @brief Initialize yolo and optical flow therad
    void initThreads();
    
    /// @brief          Perform tracking estimation, in a sequence of consistent pictures. 
    ///                 Previous frame kept in the class instance to provide consistent tracking.
    /// @param image    New frame in the sequence.
    /// @return         Type of operation preformed.
    ///     @retval     0 for normal result,
    ///     @retval     1 for yolo fails and the new bound box is generated by optical flow and momentumn,
    ///     @retval     or < 0 if an error is encountered.
    ///     @retval     -1 TRACK LOST
    int estimate(const cv::Mat& image);

    int estimate(const cv::Mat& image, int &xCenterRet, int &yCenterRet, cv::Vec4i &indiBoxRet);
    
private:
    // Models employed here
    MobileHumanPose pose_estimator;
    yolo_fast       yolo_model;

    // Momentumn of human detection box
    int momentum[2] = {0, 0};

    // Indicator of "no person has yet been detected", thus no info
    // of previous frame available. Initialized to be true.
    bool flagFirstFrame = true;

    // Initial info for trcking. Also used to restart when track lost.
    /// @todo Program a setter for these init values.
    cv::Vec4i   InitBox     = {480, 192, 560, 256};     //  This init val is for debugging
    int         xInitCenter = 520;                      //  This init val is for debugging
    int         yInitCenter = 216;                      //  This init val is for debugging

    // Keep info of previous picture to preform optical flow estimation
    cv::Mat     PrevFrame;          // Keep previous frame to estimate optical flow.
    /// @todo Aggriagate followings into a single data structure
    cv::Vec4i   PrevBox;            // Bound box (by yolo) on the previous frame. xyxy.
    cv::Vec4i   PrevIndiBox;        // Indication box of previous picture, xyxy, for visualization and optical flow tracking.
    int         xPrevCenter;        // Weighted center of the person, not the center of the box!!
    int         yPrevCenter;        // Weighted center of the person, not the center of the box!!
    unsigned    uiTLCount   = 0;    // Counter for using momentum-opti flow bound box. Hits uiMaxTLCnt is considered to be totally lost tracking.
    unsigned    uiMaxTLCnt  = 12;   // Tolerence of using momentum-opti flow bound box. 
    /// @todo Expect to have a setter for @a uiMaxTLCnt

    // Calculate detection indication box (h: head to pelvis w: 1/4h)
    // and center (avg of the head, spine and pelvis)
    
    /// @brief          Calculate detection indication box, box asp defined by @a INDIC_BOX_ASP
    ///                 and center (avg of the head, spine and pelvis)
    /// @param pose_2d 
    /// @param box 
    /// @param xCenter 
    /// @param yCenter 
    /// @return 
    cv::Vec4i getIndicationBox(const cv::Mat& pose_2d, const cv::Vec4i& box, 
                           int& xCenter, int& yCenter);

private:
    /// @brief Yolo service thread, for parallel computing with optical flow
    void yoloDetectionThread();

    // Virables related to yoloDetectionThread()
    std::mutex mtxYolo;
    std::condition_variable condVarYolo;
    bool detection_done;
    cv::Mat thread_image;
    std::vector<cv::Vec4i> thread_boxes;
    std::thread* yolo_thread;
    bool thread_running;
    
    
private:
    /// @brief              Estimate sparse optical flow for range of picture the box.
    ///                     Used here for estimate the movement of the preson been tracked.
    /// @param prevGray 
    /// @param currGray 
    /// @param box 
    /// @param visualImage 
    /// @return             pair<int, int>, movement vector (x, y)
    std::pair<int, int> calculateOpticalFlow(const cv::Mat& prevGray, const cv::Mat& currGray, 
                                            const cv::Vec4i& box, const cv::Mat& visualImage);
    
    /// @brief              Process the result of calculateOpticalFlow()
    /// @param prevPoints 
    /// @param nextPoints 
    /// @param status 
    /// @param visualImage 
    /// @return             pair<int, int>, movement vector (x, y)
    std::pair<int, int> processOpticalFlowResults(
        const std::vector<cv::Point2f>& prevPoints, 
        const std::vector<cv::Point2f>& nextPoints,
        const std::vector<uchar>& status,
        const cv::Mat& visualImage);

    /// @brief Optical flow service threead, for parallel computing with Yolo detection
    void optiFlowThread();

    // Virables related to optiFlowThread()
    std::condition_variable condVarOptiFlow;
    std::thread    *optiflow_thread;
    std::mutex      mtxOptiFlow;
    cv::Mat         thread_prevFrame;
    cv::Vec4i       thread_prevBox;
    std::vector<float> err;
    bool            optiflow_done       = false;
    int             thread_xOptiFlow    = 0;
    int             thread_yOptiFlow    = 0;
};

#endif // POSE_DETECTOR_H