#ifndef POSE_DETECTOR_H
#define POSE_DETECTOR_H

#include <opencv2/opencv.hpp>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <chrono>
#include <vector>
#include <string>
#include <cmath>

#include "yolo_fast.h"
#include "mobileHumanPose.h"
#include <opencv2/video/tracking.hpp>


#define INDIC_BOX_ASP 2.5
class HumanTracker
{
public:
    HumanTracker(const std::string& poseModelPath, const std::string& yoloModelPath, 
                int xFrameSize, int yFrameSize);
    ~HumanTracker();
    
    /// @brief Initialize yolo and optical flow therad
    void initThreads();
    
    /// @brief          Perform tracking estimation, in a sequence of consistent pictures. 
    ///                 Previous frame kept in the class instance to provide consistent tracking.
    /// @param image    New frame in the sequence.
    /// @return         Type of operation preformed.
    ///     @retval     0 for normal result,
    ///     @retval     1 for yolo fails and the new bound box is generated by optical flow and momentumn,
    ///     @retval     or < 0 if an error is encountered.
    ///     @retval     -1 TRACK LOST
    int estimate(const cv::Mat& image);

    /// @brief          Perform tracking estimation, in a sequence of consistent pictures. 
    ///                 Previous frame kept in the class instance to provide consistent tracking.
    /// @param image    New frame in the sequence.
    /// @param xCenterRet   Receive the center of the detected person
    /// @param yCenterRet   Receive the center of the detected person
    /// @param indiBoxRet   Receive the indication box of the detected person
    /// @return         Type of operation preformed.
    ///     @retval     0 for normal result,
    ///     @retval     1 for yolo fails and the new bound box is generated by optical flow and momentumn,
    ///     @retval     or < 0 if an error is encountered.
    ///     @retval     -1 TRACK LOST
    ///     @retval     -2 frame size mismatch
    int estimate(const cv::Mat& image, int &xCenterRet, int &yCenterRet, cv::Vec4i &indiBoxRet);
    
    /// @brief 设置初始跟踪位置
    /// @param initBox 初始边界框，格式为[x1, y1, x2, y2]
    /// @param xCenter 初始中心点x坐标
    /// @param yCenter 初始中心点y坐标
    void setInitPos(const cv::Vec4i& initBox, int xCenter, int yCenter);
    
    /// @brief 设置帧尺寸
    /// @param xSize 帧宽度
    /// @param ySize 帧高度
    void setFrameSize(int xSize, int ySize);

    /// @brief Reset virables to init state.
    void clear();

private:
    // Models employed here
    MobileHumanPose pose_estimator;
    yolo_fast       yolo_model;

    // 帧尺寸信息
    int xFrameSize = -1;
    int yFrameSize = -1;

    // Momentumn of human detection box
    int momentum[2] = {0, 0};

    // Indicator of "no person has yet been detected", thus no info
    // of previous frame available. Initialized to be true.
    bool flagFirstFrame = true;

    // Initial info for trcking. Also used to restart when track lost.
    cv::Vec4i   InitBox     = {0, 0, 0, 0};     //  This init val is for debugging
    int         xInitCenter = -1;                       //  This init val is for debugging
    int         yInitCenter = -1;                       //  This init val is for debugging

    // Keep info of previous picture to preform optical flow estimation
    cv::Mat     PrevFrame;          // Keep previous frame to estimate optical flow.
    /// @todo Aggriagate followings into a single data structure
    cv::Vec4i   PrevBox;            // Bound box (by yolo) on the previous frame. xyxy.
    cv::Vec4i   PrevIndiBox;        // Indication box of previous picture, xyxy, for visualization and optical flow tracking.
    int         xPrevCenter;        // Weighted center of the person, not the center of the box!!
    int         yPrevCenter;        // Weighted center of the person, not the center of the box!!
    unsigned    uiTLCount   = 0;    // Counter for using momentum-opti flow bound box. Hits uiMaxTLCnt is considered to be totally lost tracking.
    unsigned    uiMaxTLCnt  = 12;   // Tolerence of using momentum-opti flow bound box. 
    /// @todo Expect to have a setter for @a uiMaxTLCnt

    // Calculate detection indication box (h: head to pelvis w: 1/4h)
    // and center (avg of the head, spine and pelvis)
    
    /// @brief          Calculate detection indication box, box asp defined by @a INDIC_BOX_ASP
    ///                 and center (avg of the head, spine and pelvis)
    /// @param pose_2d 
    /// @param box 
    /// @param xCenter 
    /// @param yCenter 
    /// @return 
    cv::Vec4i getIndicationBox(const cv::Mat& pose_2d, const cv::Vec4i& box, 
                           int& xCenter, int& yCenter);

private:
    /// @brief Yolo service thread, for parallel computing with optical flow
    void yoloDetectionThread();

    // Virables related to yoloDetectionThread()
    std::mutex mtxYolo;
    std::condition_variable condVarYolo;
    bool detection_done;
    cv::Mat thread_image;
    std::vector<cv::Vec4i> thread_boxes;
    std::thread* yolo_thread;
    bool thread_running;
    
    
private:
    /// @brief              Estimate sparse optical flow for range of picture the box.
    ///                     Used here for estimate the movement of the preson been tracked.
    /// @param prevGray 
    /// @param currGray 
    /// @param box 
    /// @param visualImage 
    /// @return             pair<int, int>, movement vector (x, y)
    std::pair<int, int> calculateOpticalFlow(const cv::Mat& prevGray, const cv::Mat& currGray, 
                                            const cv::Vec4i& box, const cv::Mat& visualImage);
    
    /// @brief              Process the result of calculateOpticalFlow()
    /// @param prevPoints 
    /// @param nextPoints 
    /// @param status 
    /// @param visualImage 
    /// @return             pair<int, int>, movement vector (x, y)
    std::pair<int, int> processOpticalFlowResults(
        const std::vector<cv::Point2f>& prevPoints, 
        const std::vector<cv::Point2f>& nextPoints,
        const std::vector<uchar>& status,
        const cv::Mat& visualImage);

    /// @brief Optical flow service threead, for parallel computing with Yolo detection
    void optiFlowThread();

    // Virables related to optiFlowThread()
    std::condition_variable condVarOptiFlow;
    std::thread    *optiflow_thread;
    std::mutex      mtxOptiFlow;
    cv::Mat         thread_prevFrame;
    cv::Vec4i       thread_prevBox;
    std::vector<float> err;
    bool            optiflow_done       = false;
    int             thread_xOptiFlow    = 0;
    int             thread_yOptiFlow    = 0;
    
    cv::KalmanFilter kalman_filter;
    cv::Mat kalman_state;      // 状态向量
    cv::Mat kalman_measure;    // 观测向量
    bool kalman_initialized = false;
};

#endif // POSE_DETECTOR_H